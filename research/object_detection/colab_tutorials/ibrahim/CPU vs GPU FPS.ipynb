{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660b7bab",
   "metadata": {},
   "source": [
    "## SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"CUDAExecutionProvider\" # CPUExecutionProvider CUDAExecutionProvider\n",
    "if device == 'CPUExecutionProvider':\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb37b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import math\n",
    "import onnxruntime as rt\n",
    "import time\n",
    "import importlib\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import notebook\n",
    "DETRAC_TEST = '/home/ubuntu/ibrahim/master/datasets/Insight-MVT_Annotation_Test'\n",
    "th = 0.5\n",
    "os.chdir(os.path.abspath('/home/ubuntu/ibrahim/master/models/research/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23282c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"MVI_39031\"\n",
    "def calc_fps(det_elapsed: list, trac_elapsed: list):\n",
    "    det_mean = sum(det_elapsed) / float(len(det_elapsed))\n",
    "    trac_mean = sum(trac_elapsed) / float(len(trac_elapsed))\n",
    "    total = list(map(sum, zip(det_elapsed, trac_elapsed)))\n",
    "    fps_mean = sum(total) / float(len(total))\n",
    "    print('Elapsed time: : ' + str(det_mean*1000) + ' millisecond per image')\n",
    "    print('Elapsed time: : ' + str(trac_mean*1000) + ' millisecond per image')\n",
    "    print(\"FPS: \", 1/fps_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da8fc310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da3cc4971c54eacb14ca375519d631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: : 8.964769045511881 millisecond per image\n",
      "Elapsed time: : 0.7976001622725506 millisecond per image\n",
      "FPS:  102.434150841438\n"
     ]
    }
   ],
   "source": [
    "import research.object_detection.tracking.sort.sort\n",
    "from research.object_detection.tracking.sort.sort import Sort\n",
    "\n",
    "model_path = \"/home/ubuntu/ibrahim/master/training/ssd_mobilenet/base/saved_model/\"\n",
    "#model_path = \"/home/ubuntu/ibrahim/master/training/ssd_resnet/base/saved_model/\"\n",
    "drop = 2\n",
    "\n",
    "sess = rt.InferenceSession(os.path.join(model_path, \"model.onnx\"), providers=[device])\n",
    "outputs = [\"num_detections\", \"detection_boxes\", \"detection_scores\", \"detection_classes\"]\n",
    "\n",
    "det_elapsed = []\n",
    "trac_elapsed = []\n",
    "importlib.reload(research.object_detection.tracking.sort.sort)\n",
    "mot_tracker= Sort()\n",
    "i=0\n",
    "for image in notebook.tqdm(sorted(os.listdir(os.path.join(DETRAC_TEST, directory)))):\n",
    "    i+=1\n",
    "    if i%drop != 0:\n",
    "        det_elapsed.append(0)\n",
    "        trac_elapsed.append(0)\n",
    "        continue\n",
    "    image_path = os.path.join(DETRAC_TEST, directory, image)\n",
    "    img = Image.open(image_path)\n",
    "    image_np = np.asarray(img).reshape(img.size[1], img.size[0], 3)\n",
    "    height, width, _ = image_np.shape\n",
    "    input_tensor = np.expand_dims(image_np.astype(np.uint8), axis=0)\n",
    "    det_start_time = time.time()\n",
    "    result = sess.run(outputs, {\"input_tensor\": input_tensor})\n",
    "    det_elapsed.append(time.time() - det_start_time)\n",
    "    num_detections, boxes, scores, classes = result[0][0], result[1][0], result[2][0], result[3][0]\n",
    "    det = []\n",
    "    for f in range(boxes.shape[0]):\n",
    "        box = boxes[f]\n",
    "        if scores[f] > th:\n",
    "            box_top = int(box[0] * height)\n",
    "            box_left = int(box[1] * width)\n",
    "            box_bottom = int(box[2] * height)\n",
    "            box_right = int(box[3] * width)\n",
    "            det.append([box_left, box_top, box_right, box_bottom, scores[f], classes[f]])\n",
    "    \n",
    "    trac_start_time = time.time()\n",
    "    if det:\n",
    "        track_bbs_ids = mot_tracker.update(np.array(det))\n",
    "    else:\n",
    "        track_bbs_ids = mot_tracker.update()\n",
    "    trac_elapsed.append(time.time() - trac_start_time)\n",
    "calc_fps(det_elapsed, trac_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77de186",
   "metadata": {},
   "source": [
    "# DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62948dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 01:13:09.262533: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 01:13:09.937978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10037 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from research.object_detection.tracking.deep_sort.deep_sort import nn_matching\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.detection import Detection\n",
    "import research.object_detection.tracking.deep_sort.deep_sort.tracker\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.tracker import Tracker\n",
    "from research.object_detection.tracking.deep_sort.tools import generate_detections as gdet\n",
    "model_filename_deep= '/home/ubuntu/ibrahim/master/deep_sort/cosine_metric_learning/output/detrac/cosine-softmax/detrac.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename_deep,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e61c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4feb45f1da4b26b3874390ddaef321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 01:13:16.404608: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8302\n",
      "2022-02-21 01:13:16.474682: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: : 268.81930163117494 millisecond per image\n",
      "Elapsed time: : 6.126545562225134 millisecond per image\n",
      "FPS:  3.63707984756936\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/ubuntu/ibrahim/master/training/ssd_resnet/base/saved_model/\"\n",
    "\n",
    "sess = rt.InferenceSession(os.path.join(model_path, \"model.onnx\"), providers=[device])\n",
    "outputs = [\"num_detections\", \"detection_boxes\", \"detection_scores\", \"detection_classes\"]\n",
    "\n",
    "det_elapsed = []\n",
    "trac_elapsed = []\n",
    "importlib.reload(research.object_detection.tracking.deep_sort.deep_sort.tracker)\n",
    "deep_tracker = Tracker(nn_matching.NearestNeighborDistanceMetric(\"cosine\", 0.3, None))\n",
    "for image in notebook.tqdm(sorted(os.listdir(os.path.join(DETRAC_TEST, directory)))):\n",
    "    image_path = os.path.join(DETRAC_TEST, directory, image)\n",
    "    img = Image.open(image_path)\n",
    "    image_np = np.asarray(img).reshape(img.size[1], img.size[0], 3)\n",
    "    height, width, _ = image_np.shape\n",
    "    input_tensor = np.expand_dims(image_np.astype(np.uint8), axis=0)\n",
    "    det_start_time = time.time()\n",
    "    result = sess.run(outputs, {\"input_tensor\": input_tensor})\n",
    "    num_detections, boxes, scores, classes = result[0][0], result[1][0], result[2][0], result[3][0]\n",
    "    det = []\n",
    "    for f in range(boxes.shape[0]):\n",
    "        box = boxes[f]\n",
    "        if scores[f] > th:\n",
    "            box_top = int(box[0] * height)\n",
    "            box_left = int(box[1] * width)\n",
    "            box_bottom = int(box[2] * height)\n",
    "            box_right = int(box[3] * width)\n",
    "            det.append([box_left, box_top, (box_right-box_left), (box_bottom-box_top), scores[f], classes[f]])\n",
    "    if det:\n",
    "         features = encoder(image_np, np.array(det)[:, 0:4])\n",
    "    else:\n",
    "        features = encoder(image_np, np.array(det))\n",
    "    det_elapsed.append(time.time() - det_start_time)\n",
    "    detections = [Detection((bbox[0], bbox[1], bbox[2], bbox[3]), bbox[4], feature)\n",
    "                            for bbox, feature in zip(det, features)]\n",
    "    trac_start_time = time.time()\n",
    "    deep_tracker.predict()\n",
    "    deep_tracker.update(detections)\n",
    "    track_bbs_ids = []\n",
    "    for track in deep_tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue\n",
    "        track_bbs_ids.append([*track.to_tlbr(), track.track_id])\n",
    "    for track_pred in track_bbs_ids:\n",
    "        bb_w = track_pred[2] - track_pred[0]\n",
    "        bb_h = track_pred[3] - track_pred[1]\n",
    "    trac_elapsed.append(time.time() - trac_start_time)\n",
    "calc_fps(det_elapsed, trac_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1a7e9",
   "metadata": {},
   "source": [
    "# PAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5dfa39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.object_detection.tracking.deep_sort.deep_sort import nn_matching\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.detection import Detection\n",
    "import research.object_detection.tracking.deep_sort.deep_sort.tracker\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd8c761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d3cdc78abb4faba6acebd256a9aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: : 252.04627140849627 millisecond per image\n",
      "Elapsed time: : 4.293223627570535 millisecond per image\n",
      "FPS:  3.9010765776038556\n"
     ]
    }
   ],
   "source": [
    "#model_path = \"/home/ubuntu/ibrahim/master/training/ssd_mobilenet/final_embeddings/saved_model/\"\n",
    "model_path = \"/home/ubuntu/ibrahim/master/training/ssd_resnet/final_embeddings/saved_model/\"\n",
    "\n",
    "sess = rt.InferenceSession(os.path.join(model_path, \"model.onnx\"), providers=[device])\n",
    "outputs = [\"num_detections\", \"detection_boxes\", \"detection_scores\", \"detection_classes\", \"nms_embedding\"]\n",
    "\n",
    "det_elapsed = []\n",
    "trac_elapsed = []\n",
    "importlib.reload(research.object_detection.tracking.deep_sort.deep_sort.tracker)\n",
    "deep_tracker = Tracker(nn_matching.NearestNeighborDistanceMetric(\"cosine\", 0.3, None))\n",
    "for image in notebook.tqdm(sorted(os.listdir(os.path.join(DETRAC_TEST, directory)))):\n",
    "    image_path = os.path.join(DETRAC_TEST, directory, image)\n",
    "    img = Image.open(image_path)\n",
    "    image_np = np.asarray(img).reshape(img.size[1], img.size[0], 3)\n",
    "    height, width, _ = image_np.shape\n",
    "    input_tensor = np.expand_dims(image_np.astype(np.uint8), axis=0)\n",
    "    det_start_time = time.time()\n",
    "    result = sess.run(outputs, {\"input_tensor\": input_tensor})\n",
    "    det_elapsed.append(time.time() - det_start_time)\n",
    "    num_detections, boxes, scores, classes, emb = result[0][0], result[1][0], result[2][0], result[3][0], result[4][0]\n",
    "    det = []\n",
    "    features = []\n",
    "    for f in range(boxes.shape[0]):\n",
    "        box = boxes[f]\n",
    "        if scores[f] > th:\n",
    "            box_top = int(box[0] * height)\n",
    "            box_left = int(box[1] * width)\n",
    "            box_bottom = int(box[2] * height)\n",
    "            box_right = int(box[3] * width)\n",
    "            det.append([box_left, box_top, (box_right-box_left), (box_bottom-box_top), scores[f], classes[f]])\n",
    "            features.append(emb[f])\n",
    "\n",
    "    detections = [Detection((bbox[0], bbox[1], bbox[2], bbox[3]), bbox[4], feature)\n",
    "                            for bbox, feature in zip(det, features)]\n",
    "    trac_start_time = time.time()\n",
    "    deep_tracker.predict()\n",
    "    deep_tracker.update(detections)\n",
    "    track_bbs_ids = []\n",
    "    for track in deep_tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue\n",
    "        track_bbs_ids.append([*track.to_tlbr(), track.track_id])\n",
    "    for track_pred in track_bbs_ids:\n",
    "        bb_w = track_pred[2] - track_pred[0]\n",
    "        bb_h = track_pred[3] - track_pred[1]\n",
    "    trac_elapsed.append(time.time() - trac_start_time)\n",
    "calc_fps(det_elapsed, trac_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f04a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
