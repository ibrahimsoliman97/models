{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fa3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f22649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import six\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from six import BytesIO\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import importlib\n",
    "import time\n",
    "from tqdm import notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9524923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import colorsys\n",
    "\n",
    "def _get_colors(num_colors):\n",
    "    colors=[]\n",
    "    for i in np.arange(0., 360., 360. / num_colors):\n",
    "        hue = i/360.\n",
    "        lightness = (50 + np.random.rand() * 10)/100.\n",
    "        saturation = (90 + np.random.rand() * 10)/100.\n",
    "        c = colorsys.hls_to_rgb(hue, lightness, saturation)\n",
    "        c_t = tuple([int(255*x) for x in c])\n",
    "        colors.append(c_t)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff17056",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.abspath('/home/ubuntu/ibrahim/master/models/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa67bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.object_detection.tracking.deep_sort.deep_sort import nn_matching\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.detection import Detection\n",
    "import research.object_detection.tracking.deep_sort.deep_sort.tracker\n",
    "from research.object_detection.tracking.deep_sort.deep_sort.tracker import Tracker\n",
    "from research.object_detection.tracking.deep_sort.tools import generate_detections as gdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8a3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =_get_colors(200)\n",
    "random.shuffle(colors)\n",
    "def draw_sort(image, track_bbs_ids):\n",
    "    image_pil=Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    im_width, im_height = image_pil.size\n",
    "    for det in track_bbs_ids:\n",
    "        (left, right, top, bottom) = (det[0], det[2], det[1], det[3])\n",
    "        draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width=2, fill=colors[det[4]])\n",
    "        draw.text((left + 10, bottom -20),\n",
    "                    str(det[4]),\n",
    "                    fill=colors[det[4]])\n",
    "    np.copyto(image, np.array(image_pil))\n",
    "    \n",
    "def load_image_into_numpy_array(path):\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.asarray(image).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Load the COCO Label Map\n",
    "category_index = {\n",
    "    1: {'id': 1, 'name': 'car'},\n",
    "    2: {'id': 2, 'name': 'van'},\n",
    "    3: {'id': 3, 'name': 'bus'},\n",
    "    4: {'id': 4, 'name': 'others'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de4f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 23:16:11.909149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-15 23:16:15.899223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9849 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "detect_fn = tf.saved_model.load('/home/ubuntu/ibrahim/master/training/ssd_resnet/final_embeddings/saved_model/saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidoes = [{'directory': \"MVI_39211\", 'type': 'easy', 'start': 0, 'end': 300 },\n",
    "          {'directory': \"MVI_39401\", 'type': 'easy', 'start': 0, 'end': 300 },\n",
    "          {'directory': \"MVI_40712\", 'type': 'easy', 'start': 950, 'end': 1250 },\n",
    "          {'directory': \"MVI_39271\", 'type': 'medium', 'start': 100, 'end': 400 },\n",
    "          {'directory': \"MVI_40853\", 'type': 'medium', 'start': 0, 'end': 300 },\n",
    "          {'directory': \"MVI_40772\", 'type': 'medium', 'start': 800, 'end': 1100 },\n",
    "          {'directory': \"MVI_40901\", 'type': 'hard', 'start': 0, 'end': 300 },\n",
    "          {'directory': \"MVI_39511\", 'type': 'hard', 'start': 0, 'end': 300 },\n",
    "          {'directory': \"MVI_39511\", 'type': 'hard', 'start': 0, 'end': 300 }]\n",
    "DETRAC_TEST = '/home/ubuntu/ibrahim/master/datasets/Insight-MVT_Annotation_Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "671468a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidoes = [{'directory': \"MVI_39271\", 'type': 'medium', 'start': 100, 'end': 400 }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6881e219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805592e0bcb249fdbc66ef619dceff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8121b30aa0f440a3bd75e93c462d08ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 23:17:30.329206: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8302\n",
      "2022-03-15 23:17:33.589947: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    }
   ],
   "source": [
    "th = 0.3\n",
    "for ent in notebook.tqdm(vidoes):\n",
    "    directory, _type, start, end = ent['directory'],ent['type'],ent['start'],ent['end']\n",
    "    path_write = f\"/home/ubuntu/ibrahim/master/results/retina_final_embeddings/{_type}/{directory}\"\n",
    "    if not os.path.exists(path_write):\n",
    "        os.makedirs(path_write)\n",
    "    counter = 0\n",
    "    if os.path.isdir(os.path.join(DETRAC_TEST, directory)):\n",
    "        importlib.reload(research.object_detection.tracking.deep_sort.deep_sort.tracker)\n",
    "        deep_tracker = Tracker(nn_matching.NearestNeighborDistanceMetric(\"cosine\", 0.3, None))\n",
    "        for image in notebook.tqdm(sorted(os.listdir(os.path.join(DETRAC_TEST, directory)))):\n",
    "            counter += 1\n",
    "            if counter < start or counter > end:\n",
    "                continue\n",
    "            image_path = os.path.join(DETRAC_TEST, directory, image)\n",
    "            frame_no = int(image.replace('img', '').replace('.jpg', ''))\n",
    "            image_np = load_image_into_numpy_array(image_path)\n",
    "            height, width, _ = image_np.shape\n",
    "            input_tensor = np.expand_dims(image_np, 0)\n",
    "            detections = detect_fn(input_tensor)\n",
    "            boxes = detections['detection_boxes'][0].numpy()\n",
    "            classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "            scores = detections['detection_scores'][0].numpy()\n",
    "            emb = detections['nms_embedding'][0].numpy()\n",
    "            det = []\n",
    "            features = []\n",
    "            for f in range(boxes.shape[0]):\n",
    "                box = boxes[f]\n",
    "                if scores[f] > th:\n",
    "                    box_top = int(box[0] * height)\n",
    "                    box_left = int(box[1] * width)\n",
    "                    box_bottom = int(box[2] * height)\n",
    "                    box_right = int(box[3] * width)\n",
    "                    det.append([box_left, box_top, (box_right-box_left), (box_bottom-box_top), scores[f], classes[f]])\n",
    "                    features.append(emb[f])\n",
    "            detections_deep = [Detection((bbox[0], bbox[1], bbox[2], bbox[3]), bbox[4], feature)\n",
    "                                    for bbox, feature in zip(det, features)]\n",
    "            deep_tracker.predict()\n",
    "            deep_tracker.update(detections_deep)\n",
    "            track_bbs_ids = []\n",
    "            for track in deep_tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue\n",
    "                track_bbs_ids.append([*track.to_tlbr(), track.track_id])\n",
    "            image_np_with_detections = image_np.copy()\n",
    "            draw_sort(image_np_with_detections, track_bbs_ids)\n",
    "            if counter > start and counter < end and counter%25 == 0:\n",
    "                im = Image.fromarray(image_np_with_detections)\n",
    "                im.save(f\"{path_write}/{directory}_{counter}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
